\documentclass[french]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{babel}

\title{Docker}

\begin{document}
\date{}

\maketitle

\section{Docker Commmands}

\verb|docker pull|: pull an image\\

\verb|docker run <image>|: start a container, runs an instance of the image. If the image is not present it will go out to docker hub and pull the image down\\

\verb|docker ps|: list all running containers. The container id and name are randomly generated

\verb| -a |: list stopped containers also\\

\verb|docker stop <id / name>|: stop container\\

\verb|docker rm <id / name>|: remove a stopped or exited container\\

\verb|docker images|: see a list of availables images\\

\verb|docker rmi <image>|: remove an image\\

\verb|docker exec <container> <command>|: execute a command on the container\\

\verb|docker run -d <image>|: run the docker container in the background mode\\

Rq. A container only lives as long as the process inside it is alive

\section{Run commands}

\verb|docker run <image>:<version>|: run an image of that version. The default tag is `latest'\\

By default the docker container does not listen to standart input. It runs in a non interactive mode. If you want to provide your input you must map the standart input of you host to the docker container:\\

\verb|docker run -i <image>|\\
The \verb|-i| parameter is for interactive mode. For attach the terminal to the container's terminal use the \verb|-t| option:\\

\verb|docker run -it <image>|\\

\subsection{Port mapping}

If you dockerize a web server that's listening on port 5000, you can then access it by using port 5000 but what IP do you use for accesing from a web browser?
\begin{enumerate}
  \item Use the IP of the docker container. Every docker container has an IP assigned by default. It's an internal IP and only accesible within the docker host (that contains the container). So if you open the browser form within the docker host you can go to that IP.
  \item For accesing it outside the docker host you could use the IP of the docker host. But for that to work you must map the port inside the docker container to a free port on the docker host.
  \begin{verbatim}
    docker run -p 80:5000 <image>
  \end{verbatim}
\end{enumerate}

\subsection{Volume mapping}

The docker container has it's own isolated filesystem. If you have a container with a mysql image and you delete the container, all the data is deleted. If you want to persist data you would want to map a directory outside the container on the docker host to a directory inside the container.
\begin{verbatim}
  docker run -v <docker host file>:<container file> mysql
\end{verbatim}

\subsection{Inspect Container}

\verb|docker inspect <container>|: it returns all the details of a container in a json format

\subsection{Container Logs}

To view the standart output of a container use:
\begin{verbatim}
  docker logs <container>
\end{verbatim}

\section{ENV Variables}

If you have some code that takes ENV variables, once you app gets packaged into a docker image, you would then run it with the \verb|-e| option.
\begin{verbatim}
  docker run -e APP_COLOR=blue <image>
\end{verbatim}

\section{Create your own image}

Why to create your own image? It could be because you can't find a component or a service that you want to use as part of your application on docker hub or because the application that you are developping will be dockerize for ease of shipping and deployment.

Let's package a flask web server:\\
First what would be the steps to deploy the app manually:
\begin{enumerate}
  \item  operating system like ubuntu
  \item update the source repo
  \item install dependencies
  \item install python
  \item copy the source code
  \item run the web server using the flask command 
\end{enumerate}$ $

How to create the image:
\begin{enumerate}
  \item First create a docker file na,ed Dockerfile and write down the instruction for setting up the application:
\begin{verbatim}
FROM Ubuntu

RUN apt-get update
RUN apt-get install python

RUN pip install flask
RUN pip install flask-mysql

COPY . /opt/source-code

ENTRYPOINT FLASK_APP=/opt/source-code/app.py flask run
\end{verbatim}
\item build your image using the \verb|docker build| command and specify the dockerfile as input as well as a tagname for the image:
\begin{verbatim}
  docker build Dockerfile -t my-custom-app
\end{verbatim}
This will create an image locally on your system
\item to make it available on the docker hub registry use
\begin{verbatim}
  docker push my-custom-app
\end{verbatim}
\end{enumerate}

\subsection{The Dockerfile}

The dockerfile is a text file written in a specific format. Every docker image must be based of another image. Either an OS or anoher image based on an OS. \\
\verb|ENTRYPOINT| allows us to specify a command that will be run when the image is runned as a container.

\section{Command arguments}

\verb|CMD| default command for an image. It's possible to override the default command for an image by creating a new image from it with \verb|FROM image| and oveeride then the \verb|CMD|
It's also possible to do it when running the image:
\begin{verbatim}
  docker run ubuntu sleep 5
\end{verbatim}

The \verb|ENTRYPOINT| instruction is like the command instruction \verb|CMD| as in you can specify the program that will be runned when the container starts. What's different is that whatever you specify on the command line will get appended to the entry point. In case of the command line parameters passed will get replaced entirely.

It's possible to use both in case you want a default value for the \verb|ENTRYPOINT|. In this case the \verb|CMD| instruction will be appended to the \verb|ENTRYPOINT| instruction.

\section{Networking}

When you install docker it creates three networks automatically: Bridge, none, host. Bridge is the default network a container gets attached to. If you would like to associate the container with any other network you can specify the network information:
\begin{verbatim}
  docker run Ubuntu --network=none
\end{verbatim}
\begin{itemize}
  \item [-] The Bridge network is a private internal network created by docker on the host. Containers get attached to it by default and get an internal IP adress. The containers can access each other using this internal IP. To access any of these container to the outside world, map the ports of these containers to ports on the docker host.
  \item [-] Another way to access a container from the outside is by associating it to the host network. This take out any isolation between the docker host and the docker container. You don't need to map the ports but you can't run several containers on the same port anymore. As the ports are now common to all containers.
  \item [-] With the none network the containers are not attached to any network and doesn't have any access to the external network or other containers. They are in an isolated network.
\end{itemize}$ $

By default docker only creates one internal Bridge network. We can create our own iternal networks using the command:
\begin{verbatim}
  docker network create \
    --driver bridge \
    --subnet 182.18.0.0/16
    custom-isolated-network
\end{verbatim}

\verb|docker network ls|: list all networks

\subsection{Embedded DNS}

Suppose you have a web container and a mysql container. You want to access mysql from the server and both are on the same network. You could access mysql with its ip but it's not ideal because it could change. The right way to do it is to use the container name. All containers in a docker host can resolve each other with the name of the container. Docker has a built in DNS server.

Docker uses network namespaces that creates a separate namespace for each container. It then uses virtual ethernet pairs to connect the containers together.

\section{Storage}

When you install docker all files related to container and images and others are stored in \verb|/var/lib/docker/|\\

You can add a persistent volume to a container. For that first create a volume:
\begin{verbatim}
  docker volume create data_volume
\end{verbatim}
This creates a directory \verb|volumes| in \verb|/var/lib/docker/| and a subdirectory \verb|data_volume| inside it.\\

You can then run the docker container with the volume:
\begin{verbatim}
  docker run -v data_volume:<location_inside_container> mysql
\end{verbatim}
This will mount the volume into the specified directory. So all data is stored in the volume on the docker host. Even if the container is destroyed, the data is still active.\\

Rq. If you run the \verb|docker run -v| before actually creating the volume, docker will create for you.\\

If you want to store data in the docker host outside the default \verb|/var/lib/docker/volumes| you have to run the container with the complete path of the volume:
\begin{verbatim}
  docker run -v /data/mysql:<location_inside_container> mysql
\end{verbatim}
This is called bind mounting (vs volume mounting)\\

Rq. The \verb|-v| is the old way of doing the new way is with the \verb|--mount| parameter:
\begin{verbatim}
  docker run \
    --mount type=bind,source=/data/mysql,target=/var/lib/mysql mysql
\end{verbatim}

\section{Docker compose}

If we need to setup a complex application running multiple services, a better way to do it is to use \verb|docker-compose|. With docker compose we could create a configuration file in yaml format called \verb|docker-compose.yaml| and put together the different services and the options specific to running them.
\begin{verbatim}
services:
  web:
    image: "simple-webapp"
  database:
    image: "mongodb"
  messaging:
    image: "redis:alpine"
  orchestration:
    image: "ansible"
\end{verbatim}

And then just use the:
\begin{verbatim}
  docker-compose up
\end{verbatim}

\subsection{Example, voting app}

App flow:
\begin{enumerate}
  \item voting-app front (python)
  \item in-memory DB (reddis)
  \item worker (.NET)
  \item db (postreSQL)
  \item result-app (Node)
\end{enumerate}

\subsubsection{Docker run commands}
\begin{verbatim}
  docker run -d --name=redis redis (-d to add container in bg)
  docker run -d --name=db postgres:9.4
  docker run -d --name=vote -p 5000:80 voting-app
  docker run -d --name=result -p 5001:80 result-app
  docker run -d --name=worker worker
\end{verbatim}

You need to create the links between the containers
\begin{verbatim}
  docker run -d --name=redis redis (-d to add container in bg)
  docker run -d --name=db --link db:db postgres:9.4
  docker run -d --name=vote -p 5000:80 --link redis:redis voting-app
    (--link <container_name>:<host_name>)
  docker run -d --name=result -p 5001:80 result-app
  docker run -d --name=worker --link db:db --link redis:redis worker
\end{verbatim}

Rq. Using links this way is deprecated.

\subsubsection{Docker compose}

Container names are the keys:
\begin{verbatim}
redis:
  image: redis
db:
  image: postgres:9.4
vote:
  image: voting-app
  ports:
    - 5000:80
  links:
    - redis
result:
  image: result-app
  ports:
    - 5001:80
  links:
    - db
worker:
  image: worker
  links:
    - redis
    - db
\end{verbatim}

Rq. \verb|db:db| $\Leftrightarrow$ \verb|db|

\subsection{Docker compose build}

We assumed all docker images were already built. redis and postgres are official images and already available on docker hub but the other three are not. If we would like to instruct docker-compose to run a docker build instead of trying to pull an image we could replace the \verb|image| line with a \verb|build| line and specify the location of a directory which contains the application code and a Dockerfile.
\begin{verbatim}
  vote:
    build: ./vote
  result:
    build: ./result
  worker:
    build: ./worker
\end{verbatim}

\subsubsection{Versions}

For version 2 and up you must specify the version of the docker compose:
\begin{verbatim}
  version: 2
  services:
    redis:
      image: redis
    db:
      image: postgres:9.4
    vote:
      image: voting-app
      ports:
        - 5000:80
\end{verbatim}

In version 1, docker compose attaches all the containers to the default Bridge network and then use links to allow communication.

With version 2, docker compose automatically creates a dedicated Bridge network for the application and attaches all containers to that new network. All containers are then able to communicate using each others service names so you don't need links in version 2.

Version 2 also introduces a depends on feature. If you wish to specify a starting order. So if the voting app is depending on the redis service you need to ensure the redis container is started first.
\begin{verbatim}
  vote:
    image: voting-app
    ports:
      - 5000:80
    depends_on:
      - redis
\end{verbatim}

Then comes version 3. Similar to version 2 with support to docker swarm.

\subsubsection{Networks}

Suppose we want to create two networks to separate the front and the back. We would have the voting app and result app connected to the front and everything connected to the back.

\begin{verbatim}
  version: 2
  services:
    redis:
      image: redis
      networks:
        - back-end
    db:
      image: postgres:9.4
      networks:
        - back-end
    vote:
      image: voting-app
      ports:
        - 5000:80
      networks:
        - front-end
        - back-end
    result:
      image: result-app
      ports:
        - 5001:80
      networks:
        - front-end
        - back-end
    worker:
      image: worker
      networks:
        - back-end
  networks:
    front-end
    back-end
\end{verbatim}

\section{Docker registry}

When running an image for example \verb|docker run nginx|, docker needs an image repository here it's nginx but it also needs a user/account. If none is provided docker assumes it's the same as the docker image so here we would have nginx/nginx. Where does docker pull the image from ? If no registry is specified, it uses the default docker.io (docker hub). The registry is where all the images are stored.
\begin{verbatim}
  docker.io/nginx/nginx
\end{verbatim}

\end{document}
